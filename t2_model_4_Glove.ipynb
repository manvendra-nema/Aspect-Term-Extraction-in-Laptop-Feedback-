{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTExoSN2ShWl",
    "outputId": "6ad3d699-da2d-4257-ec33-6ef2d51a4741"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1JXz9D9SEdxy"
   },
   "outputs": [],
   "source": [
    "\n",
    "# import json\n",
    "# def convert_to_bilou_format(raw_data):\n",
    "#     bilou_data = {}\n",
    "\n",
    "#     for index, case_data in enumerate(raw_data):\n",
    "#         raw_words = case_data[\"raw_words\"]\n",
    "#         words = case_data[\"words\"]\n",
    "#         aspects = case_data[\"aspects\"]\n",
    "#         opinions = case_data[\"opinions\"]\n",
    "\n",
    "#         bilou_labels = ['O'] * len(words)\n",
    "\n",
    "#         for aspect in aspects:\n",
    "#             for idx,i in enumerate(range(aspect[\"from\"], aspect[\"to\"])):\n",
    "#                 if i == aspect[\"from\"]:\n",
    "#                     bilou_labels[i] = 'B'\n",
    "#                 else:\n",
    "#                     bilou_labels[i] = 'I'\n",
    "\n",
    "#         # for opinion in opinions:\n",
    "#         #     for idx,i in enumerate(range(opinion[\"from\"], opinion[\"to\"])):\n",
    "#         #         bilou_labels[i] = 'B_' + opinion[\"term\"][idx]\n",
    "\n",
    "#         bilou_data[index] = {\n",
    "#             \"text\": raw_words,\n",
    "#             \"labels\": bilou_labels\n",
    "#         }\n",
    "#     # print(bilou_data)\n",
    "#     return bilou_data\n",
    "\n",
    "# # Your JSON data\n",
    "# # Read input data from a JSON file\n",
    "# for i in [\"Train\",\"Test\",\"Val\"]:\n",
    "#   with open(f\"D:/Downloads/Laptop_Review_{i}.json\", 'r') as json_file:\n",
    "    \n",
    "#       raw_data = json.load(json_file)\n",
    "\n",
    "#   # Convert to BILOU format\n",
    "#   bilou_data = convert_to_bilou_format(raw_data)\n",
    "\n",
    "#   # Save the output to a JSON file\n",
    "#   with open(f'bilou_data_{i}.json', 'w') as json_file:\n",
    "#       json.dump(bilou_data, json_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQkdf-XdEnfJ",
    "outputId": "3f5cddd8-f811-4123-9638-70a6312487a4"
   },
   "outputs": [],
   "source": [
    "# !pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWR6lMXiEpYS",
    "outputId": "12ecc080-2afe-4116-e5dc-cafc70d4fa51"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import gensim.downloader as api\n",
    "from torchtext.vocab import GloVe\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import fasttext.util\n",
    "import json\n",
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, json_path, embedding_type='word2vec',load=True):\n",
    "        with open(json_path, 'r') as file:\n",
    "            self.data = json.load(file)\n",
    "\n",
    "        self.embedding_type = embedding_type\n",
    "        if load:\n",
    "          self.embedding_model =self.load_embedding_model()\n",
    "        else:\n",
    "          self.embedding_model = None\n",
    "\n",
    "    def load_embedding_model(self):\n",
    "        if self.embedding_type == 'word2vec':\n",
    "            # Download the pre-trained Word2Vec model\n",
    "            return api.load('word2vec-google-news-300')\n",
    "        elif self.embedding_type == 'glove':\n",
    "            # Download the pre-trained GloVe model (6B tokens, 300d)\n",
    "            return GloVe(name='6B', dim=300)\n",
    "        elif self.embedding_type == 'fasttext':\n",
    "            # Load the pre-trained FastText model\n",
    "            fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "            ft = fasttext.load_model('cc.en.300.bin')\n",
    "            return fasttext.load_model('cc.en.300.bin')  # Adjust the path based on your downloaded model\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "\n",
    "    def text_to_embeddings(self, text):\n",
    "        maxlen = 100\n",
    "        if self.embedding_type == 'word2vec':\n",
    "            # Word2Vec embeddings\n",
    "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(self.embedding_model.vector_size) for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            embeddings = [torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]\n",
    "\n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "\n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((self.embedding_model.vector_size,),-1.0))\n",
    "\n",
    "\n",
    "        elif self.embedding_type == 'glove':\n",
    "            # GloVe embeddings\n",
    "            embeddings = [self.embedding_model[word]  for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
    "\n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "\n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
    "\n",
    "        elif self.embedding_type == 'fasttext':\n",
    "            # FastText embeddings\n",
    "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(sentiment_dataset.embedding_model['a'].shape[0]) for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
    "\n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "\n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "        # print()\n",
    "        return np.stack(embeddings)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "\n",
    "        index = str(index)\n",
    "        text = self.data[index][\"text\"]\n",
    "        labels = self.data[index][\"labels\"]\n",
    "\n",
    "        # Convert text to embeddings\n",
    "        text_embeddings = torch.tensor(self.text_to_embeddings(text))\n",
    "        # print(text_embeddings.shape)\n",
    "        # torch.stack([torch.full((1,text_embeddings.shape[1]),-1000),text_embeddings, [torch.full((1,text_embeddings.shape[1]),1000)])\n",
    "        current_length = len(labels)\n",
    "\n",
    "        labels = ['<START>'] + labels + ['<STOP>']\n",
    "\n",
    "        sent_lengths =torch.tensor(len(labels))\n",
    "\n",
    "        max_length = 100\n",
    "        labels = labels + ['<PAD>'] * (max_length - (current_length+2))\n",
    "\n",
    "        # Convert labels to numerical format if needed\n",
    "        label_mapping = {'O': 0, 'B': 1, 'I':2,'<START>':3,'<STOP>':4,'<PAD>':5}                               # bind it to self__________________________\n",
    "        numerical_labels = [label_mapping[label] for label in labels ]\n",
    "\n",
    "\n",
    "        # Pad the sequence to the maximum length\n",
    "\n",
    "        # Convert labels to PyTorch tensor\n",
    "        labels_tensor = torch.tensor(numerical_labels)\n",
    "        mask = torch.hstack([torch.full((text_embeddings.shape[0],),True),torch.full((100-text_embeddings.shape[0],),False)])\n",
    "        # print(labels_tensor.shape,text_embeddings.shape,mask.shape)\n",
    "        return text_embeddings, labels_tensor, mask,sent_lengths\n",
    "\n",
    "# Example usage\n",
    "\n",
    "json_path = 'ATE_train.json'\n",
    "embedding_type = 'glove'\n",
    "sentiment_dataset = SentimentAnalysisDataset(json_path, embedding_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_dataset.embedding_model['MANVENEDDADAD njjjjfdsjsffksnkfshdhfnd//598457^*^^%^NEKNNF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Text Embeddings: tensor([[-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,\n",
      "         -1.0000e+03, -1.0000e+03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.5973e-01,  1.1896e-01, -1.1889e-01,  ...,  7.3040e-02,\n",
      "         -3.6124e-01, -3.0208e-01],\n",
      "        ...,\n",
      "        [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
      "         -1.0000e+00, -1.0000e+00],\n",
      "        [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
      "         -1.0000e+00, -1.0000e+00],\n",
      "        [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
      "         -1.0000e+00, -1.0000e+00]])\n",
      "Sample Labels: tensor([3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 4, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sentiment_dataset.embedding_model= temp.embedding_model\n",
    "# Accessing a sample from the dataset\n",
    "sample_text_embeddings, sample_labels, mask,s_len = sentiment_dataset[0]\n",
    "print(\"Sample Text Embeddings:\", sample_text_embeddings)\n",
    "print(\"Sample Labels:\", sample_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "G422-_yypz-F"
   },
   "outputs": [],
   "source": [
    "json_path = 'ATE_val.json'\n",
    "sentiment_dataset_val = SentimentAnalysisDataset(json_path, embedding_type,load=False)\n",
    "sentiment_dataset_val.embedding_model = sentiment_dataset.embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "__2DRx7cZCHc"
   },
   "outputs": [],
   "source": [
    "json_path = 'ATE_test.json'\n",
    "sentiment_dataset_test = SentimentAnalysisDataset(json_path, embedding_type,load=False)\n",
    "sentiment_dataset_test.embedding_model = sentiment_dataset.embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LFBQa6YRVtdP",
    "outputId": "0da2efdc-2791-4c60-dc47-7842ffa97957"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 300])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RYxdZmFAgRM9",
    "outputId": "ff634a33-1896-40e4-b371-eb5c0915a5c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iq4DRTWGXzxL",
    "outputId": "61c79d3c-9010-42f0-ceeb-a5963f9c95e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "QOxk1a5sTXtN"
   },
   "outputs": [],
   "source": [
    "batch_size  = 256\n",
    "dataloader = DataLoader(sentiment_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pige-BQNLYbz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "wdA2HAHVqBrT"
   },
   "outputs": [],
   "source": [
    "batch_size  = 256\n",
    "dataloader_val = DataLoader(sentiment_dataset_val, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7PRU5YYtEtqs"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class BiLSTMCRF(nn.Module):\n",
    "    def __init__(self, tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256):\n",
    "        \"\"\" Initialize the model\n",
    "        Args:\n",
    "            sent_vocab (Vocab): vocabulary of words\n",
    "            tag_vocab (Vocab): vocabulary of tags\n",
    "            embed_size (int): embedding size\n",
    "            hidden_size (int): hidden state size\n",
    "        \"\"\"\n",
    "        super(BiLSTMCRF, self).__init__()\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # self.sent_vocab = sent_vocab\n",
    "        self.tag_vocab = tag_vocab\n",
    "        # self.embedding = nn.Embedding(len(sent_vocab), embed_size) print\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, bidirectional=True)\n",
    "        self.hidden2emit_score = nn.Linear(hidden_size * 2, len(self.tag_vocab))\n",
    "        self.transition = nn.Parameter(torch.randn(len(self.tag_vocab), len(self.tag_vocab)))  # shape: (K, K)\n",
    "\n",
    "    def forward(self, sentences,mask, tags, sen_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "                                of the longest sentence\n",
    "            tags (tensor): corresponding tags, shape (b, len)\n",
    "            sen_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            loss (tensor): loss on the batch, shape (b,)\n",
    "        \"\"\"\n",
    "        # mask = (sentences != self.sent_vocab[self.sent_vocab.PAD])  # shape: (b, len)                        #$$$$$$$$$$$$$$$$$$$__________________\n",
    "        sentences = sentences.transpose(0, 1)  # shape: (len, b)\n",
    "        # print(\"forword--1\",sentences.shape)\n",
    "        # sentences = self.embedding(sentences)  # shape: (len, b, e)\n",
    "        emit_score = self.encode(sentences, sen_lengths)  # shape: (b, len, K)\n",
    "        # print(\"forword--2\",sentences.shape)\n",
    "        loss = self.cal_loss(tags, mask, emit_score)  # shape: (b,)\n",
    "        return loss\n",
    "\n",
    "    def encode(self, sentences, sent_lengths):\n",
    "        \"\"\" BiLSTM Encoder\n",
    "        Args:\n",
    "            sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
    "            sent_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            emit_score (tensor): emit score, shape (b, len, K)\n",
    "        \"\"\"\n",
    "        # padded_sentences = pack_padded_sequence(sentences, sent_lengths)\n",
    "        hidden_states, _ = self.encoder(sentences)\n",
    "        # print(hidden_states.shape,\"(((())))\")\n",
    "        hidden_states = hidden_states.permute(1,0,2)\n",
    "        # hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
    "        # print(hidden_states.shape)\n",
    "        emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
    "        emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
    "        return emit_score\n",
    "\n",
    "    # def encode(self, sentences, sent_lengths):\n",
    "    #   \"\"\" BiLSTM Encoder\n",
    "    #   Args:\n",
    "    #       sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
    "    #       sent_lengths (list): sentence lengths\n",
    "    #   Returns:\n",
    "    #       emit_score (tensor): emit score, shape (b, len, K)\n",
    "    #   \"\"\"\n",
    "    #   sorted_lengths, sorted_idx = torch.sort(sent_lengths, descending=True)\n",
    "    #   sorted_sentences = sentences[:, sorted_idx, :]  # Sort the sentences based on lengths\n",
    "    #   packed_sentences = pack_padded_sequence(sorted_sentences, sorted_lengths)\n",
    "    #   hidden_states, _ = self.encoder(packed_sentences)\n",
    "    #   hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
    "    #   emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
    "    #   emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
    "    #   return emit_score\n",
    "\n",
    "    def cal_loss(self, tags, mask, emit_score):\n",
    "        \"\"\" Calculate CRF loss\n",
    "        Args:\n",
    "            tags (tensor): a batch of tags, shape (b, len)\n",
    "            mask (tensor): mask for the tags, shape (b, len), values in PAD position is 0\n",
    "            emit_score (tensor): emit matrix, shape (b, len, K)\n",
    "        Returns:\n",
    "            loss (tensor): loss of the batch, shape (b,)\n",
    "        \"\"\"\n",
    "        batch_size, sent_len = tags.shape\n",
    "        # calculate score for the tags\n",
    "        score = torch.gather(emit_score, dim=2, index=tags.unsqueeze(dim=2)).squeeze(dim=2)  # shape: (b, len)\n",
    "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
    "        total_score = (score * mask.type(torch.float)).sum(dim=1)  # shape: (b,)\n",
    "        # calculate the scaling factor\n",
    "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "        fix_length = 100\n",
    "        # for i in range(1, sent_len):\n",
    "        for i in range(1, fix_length):\n",
    "            n_unfinished = mask[:, i].sum()\n",
    "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "            emit_and_transition = emit_score[: n_unfinished, i].unsqueeze(dim=1) + self.transition  # shape: (uf, K, K)\n",
    "            log_sum = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "            max_v = log_sum.max(dim=1)[0].unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
    "            log_sum = log_sum - max_v  # shape: (uf, K, K)\n",
    "            d_uf = max_v + torch.logsumexp(log_sum, dim=1).unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
    "            d = torch.cat((d_uf, d[n_unfinished:]), dim=0)\n",
    "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "        max_d = d.max(dim=-1)[0]  # shape: (b,)\n",
    "        d = max_d + torch.logsumexp(d - max_d.unsqueeze(dim=1), dim=1)  # shape: (b,)\n",
    "        llk = total_score - d  # shape: (b,)\n",
    "        loss = -llk  # shape: (b,)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def predict(self, sentences, mask, sen_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "                                of the longest sentence\n",
    "            sen_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            tags (list[list[str]]): predicted tags for the batch\n",
    "        \"\"\"\n",
    "        batch_size = sentences.shape[0]\n",
    "\n",
    "        w = mask\n",
    "        sentences = sentences.transpose(0, 1)\n",
    "\n",
    "        emit_score = self.encode(sentences, sen_lengths)\n",
    "\n",
    "        # Initialize the tags with all possible tag indices for each sentence in the batch\n",
    "        tags = [[[i] for i in range(len(self.tag_vocab))]] * batch_size  # list, shape: (b, K, 1)\n",
    "\n",
    "        # Initialize the first column of the dynamic programming matrix\n",
    "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "\n",
    "        # Use a fixed length (e.g., 100) instead of max(sen_lengths)\n",
    "        fixed_length = 100\n",
    "\n",
    "        # Iterate over the remaining columns of the dynamic programming matrix\n",
    "        for i in range(1, fixed_length):\n",
    "            # Calculate the number of unfinished sentences at the current position\n",
    "            n_unfinished = mask[:, i].sum()\n",
    "\n",
    "            # Slice the dynamic programming matrix for the unfinished sentences\n",
    "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "\n",
    "            # Compute emission and transition scores for the current position\n",
    "            emit_and_transition = self.transition + emit_score[: n_unfinished, i].unsqueeze(dim=1)  # shape: (uf, K, K)\n",
    "\n",
    "            # Compute the new values for the dynamic programming matrix\n",
    "            new_d_uf = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "\n",
    "            # Update the dynamic programming matrix and get the indices of maximum values\n",
    "            d_uf, max_idx = torch.max(new_d_uf, dim=1)\n",
    "            max_idx = max_idx.tolist()  # list, shape: (nf, K)\n",
    "\n",
    "            # Update the tags for the unfinished sentences\n",
    "            tags[: n_unfinished] = [[tags[b][k] + [j] for j, k in enumerate(max_idx[b])] for b in range(n_unfinished)]\n",
    "\n",
    "            # Concatenate the new values to the dynamic programming matrix\n",
    "            d = torch.cat((torch.unsqueeze(d_uf, dim=1), d[n_unfinished:]), dim=0)  # shape: (b, 1, K)\n",
    "\n",
    "        # Remove the singleton dimension to get the final dynamic programming matrix\n",
    "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "\n",
    "        # Get the indices of the maximum values in the final column of the matrix\n",
    "        _, max_idx = torch.max(d, dim=1)  # shape: (b,)\n",
    "        max_idx = max_idx.tolist()\n",
    "\n",
    "        # Extract the predicted tags based on the maximum indices\n",
    "        tags = [tags[b][k] for b, k in enumerate(max_idx)]\n",
    "\n",
    "        # Print the predicted tags and sentence lengths for debugging\n",
    "        # print(tags, sen_lengths, '((()))')\n",
    "\n",
    "        return tags\n",
    "\n",
    "    # def predict(self, sentences,mask, sen_lengths):\n",
    "    #     \"\"\"\n",
    "    #     Args:\n",
    "    #         sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "    #                             of the longest sentence\n",
    "    #         sen_lengths (list): sentence lengths\n",
    "    #     Returns:\n",
    "    #         tags (list[list[str]]): predicted tags for the batch\n",
    "    #     \"\"\"\n",
    "    #     batch_size = sentences.shape[0]\n",
    "    #     # w = (sentences != self.sent_vocab[self.sent_vocab.PAD])  # shape: (b, len)\n",
    "    #     w = mask\n",
    "    #     sentences = sentences.transpose(0, 1)  # shape: (len, b)\n",
    "    #     # sentences = self.embedding(sentences)  # shape: (len, b, e)\n",
    "    #     emit_score = self.encode(sentences, sen_lengths)  # shape: (b, len, K)\n",
    "    #     tags = [[[i] for i in range(len(self.tag_vocab))]] * batch_size  # list, shape: (b, K, 1)\n",
    "    #     d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "    #     for i in range(1, sen_lengths[0]):\n",
    "    #         n_unfinished = mask[:, i].sum()\n",
    "    #         d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "    #         emit_and_transition = self.transition + emit_score[: n_unfinished, i].unsqueeze(dim=1)  # shape: (uf, K, K)\n",
    "    #         new_d_uf = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "    #         d_uf, max_idx = torch.max(new_d_uf, dim=1)\n",
    "    #         max_idx = max_idx.tolist()  # list, shape: (nf, K)\n",
    "    #         tags[: n_unfinished] = [[tags[b][k] + [j] for j, k in enumerate(max_idx[b])] for b in range(n_unfinished)]\n",
    "    #         d = torch.cat((torch.unsqueeze(d_uf, dim=1), d[n_unfinished:]), dim=0)  # shape: (b, 1, K)\n",
    "    #     d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "    #     _, max_idx = torch.max(d, dim=1)  # shape: (b,)\n",
    "    #     max_idx = max_idx.tolist()\n",
    "    #     tags = [tags[b][k] for b, k in enumerate(max_idx)]\n",
    "    #     print(tags,sen_lengths,'((()))')\n",
    "    #     return tags\n",
    "\n",
    "    # def save(self, filepath):\n",
    "    #     params = {\n",
    "    #         'sent_vocab': self.sent_vocab,\n",
    "    #         'tag_vocab': self.tag_vocab,\n",
    "    #         'args': dict(dropout_rate=self.dropout_rate, embed_size=self.embed_size, hidden_size=self.hidden_size),\n",
    "    #         'state_dict': self.state_dict()\n",
    "    #     }\n",
    "    #     torch.save(params, filepath)\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     sent_vocab = Vocab.load('./vocab/sent_vocab.json')\n",
    "#     tag_vocab = Vocab.load('./vocab/tag_vocab.json')\n",
    "#     train_data, dev_data = utils.generate_train_dev_dataset('./data/train.txt', sent_vocab, tag_vocab)\n",
    "#     device = torch.device('cpu')\n",
    "#     model = BiLSTMCRF(sent_vocab, tag_vocab)\n",
    "#     model.to(device)\n",
    "#     model.save('./model/model.pth')\n",
    "#     model = model.load('./model/model.pth', device)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    # main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "argnny6HH0Tu"
   },
   "outputs": [],
   "source": [
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "tag_to_ix ={'O': 0, 'B': 1, 'I':2,'<START>':3,'<STOP>':4,'<PAD>':5}\n",
    "# tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
    "model  = BiLSTMCRF(tag_to_ix,dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
    "\n",
    "import torch.optim as optim\n",
    "learning_rate = 0.0001\n",
    "momentum = 0.9  # Optional: You can adjust the momentum term\n",
    "\n",
    "# Create an instance of the SGD optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "oHr2iehwItKL"
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import torch\n",
    "\n",
    "# # Assuming you have a BiLSTM_CRF model, a dataloader, and an optimizer\n",
    "# # Also assuming you have defined the necessary variables (e.g., vocab_size, tag_to_ix, etc.)\n",
    "\n",
    "# # Move the model to GPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Check predictions before training\n",
    "# for epoch in range(300):\n",
    "#     total_loss = 0\n",
    "#     correct_predictions = 0\n",
    "#     total_sentences = 0\n",
    "\n",
    "#     # Wrap your dataloader with tqdm for a progress bar\n",
    "#     for sentence_in, targets, mask, sen_lengths in tqdm(dataloader, desc=f'Epoch {epoch + 1}/{300}', leave=False):\n",
    "#         # Move input data to GPU\n",
    "#         sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths\n",
    "\n",
    "#         model.zero_grad()\n",
    "\n",
    "#         # Forward pass\n",
    "#         loss = model(sentence_in, mask, targets, sen_lengths)\n",
    "\n",
    "#         # Backward pass and optimization\n",
    "#         loss = torch.sum(loss)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Accumulate loss for the epoch\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#         # Update total sentences count\n",
    "#         total_sentences += sentence_in.size(0)\n",
    "\n",
    "#     # Calculate average loss for the epoch\n",
    "#     average_loss = total_loss / total_sentences\n",
    "\n",
    "#     # Print loss for each epoch\n",
    "#     print(f'Epoch {epoch + 1}/{300}, Loss: {average_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8465903IIQiP",
    "outputId": "c8b2e12f-ca29-417b-b807-260415614766"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3])==torch.tensor([1,5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2mAtfLRzkl3",
    "outputId": "7aac4995-7c39-4174-e60e-f17baf7ea0ad"
   },
   "outputs": [],
   "source": [
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c9efc196b9ec47ddbb80f91ebf9c89ab",
      "b951c48572d14bff8ce7ed3973bbc5e1",
      "0cec9bf164bf4843a65b6c49cb2ba8ec",
      "01f19ee3c41d4453922eadc27e4aebbe",
      "ad4e07d0d4af40a7bbec5532c247509e",
      "de667a0bfcfe4f309becaca01c776e41",
      "63961d90d5c243ccb3873be0a41d9f0e",
      "6826f2f8776c4f64b566c7d2eb7aada8"
     ]
    },
    "id": "5tA2FjdzzM4R",
    "outputId": "bdd0ee0d-7799-46e3-8154-84d880949277"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmanvendra\u001b[0m (\u001b[33miiitd\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Manvendra Nema\\Notebooks\\Untitled Folder 1\\wandb\\run-20240310_100108-3f6jm0dh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P1/runs/3f6jm0dh' target=\"_blank\">glv-D2-ff-cc</a></strong> to <a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P1' target=\"_blank\">https://wandb.ai/iiitd/NLP_AS2-Q3-P1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P1/runs/3f6jm0dh' target=\"_blank\">https://wandb.ai/iiitd/NLP_AS2-Q3-P1/runs/3f6jm0dh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/150, Loss: 14.3638, Accuracy: 0.3755, F1: 0.1208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 1/150, Loss: 7.5847, Accuracy: 0.8557, F1: 0.1568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/150, Loss: 8.3199, Accuracy: 0.6673, F1: 0.2135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 2/150, Loss: 2.8678, Accuracy: 0.9014, F1: 0.3243\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/150, Loss: 6.2373, Accuracy: 0.8963, F1: 0.3880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 3/150, Loss: 5.6274, Accuracy: 0.9526, F1: 0.5892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/150, Loss: 4.6796, Accuracy: 0.8178, F1: 0.4094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 4/150, Loss: 1.2917, Accuracy: 0.9522, F1: 0.4921\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/150, Loss: 2.3185, Accuracy: 0.7841, F1: 0.3997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 5/150, Loss: 1.7243, Accuracy: 0.9518, F1: 0.4905\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/150, Loss: 2.2470, Accuracy: 0.8603, F1: 0.4112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 6/150, Loss: 1.2990, Accuracy: 0.9518, F1: 0.4905\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/150, Loss: 1.7786, Accuracy: 0.8314, F1: 0.4384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 7/150, Loss: 0.8436, Accuracy: 0.9526, F1: 0.6406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/150, Loss: 1.5539, Accuracy: 0.8936, F1: 0.4372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 8/150, Loss: 0.9720, Accuracy: 0.9524, F1: 0.5901\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/150, Loss: 1.1639, Accuracy: 0.8145, F1: 0.4817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 9/150, Loss: 0.2451, Accuracy: 0.9634, F1: 0.7558\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/150, Loss: 1.1665, Accuracy: 0.9124, F1: 0.4458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 10/150, Loss: 0.9635, Accuracy: 0.9526, F1: 0.5914\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/150, Loss: 1.0873, Accuracy: 0.8437, F1: 0.4729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 11/150, Loss: 0.4492, Accuracy: 0.9165, F1: 0.6700\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/150, Loss: 0.9012, Accuracy: 0.9009, F1: 0.4554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 12/150, Loss: 0.6702, Accuracy: 0.9531, F1: 0.5933\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/150, Loss: 0.7262, Accuracy: 0.8197, F1: 0.5064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 13/150, Loss: 0.3934, Accuracy: 0.8886, F1: 0.7579\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/150, Loss: 0.6818, Accuracy: 0.9043, F1: 0.4986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 14/150, Loss: 0.6186, Accuracy: 0.9535, F1: 0.6021\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/150, Loss: 0.6651, Accuracy: 0.8887, F1: 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 15/150, Loss: 0.4427, Accuracy: 0.8977, F1: 0.6948\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/150, Loss: 0.5710, Accuracy: 0.8997, F1: 0.5097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 16/150, Loss: 0.4033, Accuracy: 0.9567, F1: 0.6344\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/150, Loss: 0.4940, Accuracy: 0.8811, F1: 0.5277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 17/150, Loss: 0.1981, Accuracy: 0.9567, F1: 0.7974\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/150, Loss: 0.4043, Accuracy: 0.9212, F1: 0.5409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 18/150, Loss: 0.3557, Accuracy: 0.9578, F1: 0.6390\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/150, Loss: 0.4159, Accuracy: 0.9132, F1: 0.5327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 19/150, Loss: 0.2117, Accuracy: 0.9639, F1: 0.7900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/150, Loss: 0.3781, Accuracy: 0.9252, F1: 0.5298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 20/150, Loss: 0.2487, Accuracy: 0.9650, F1: 0.7168\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 21/150, Loss: 0.3405, Accuracy: 0.9040, F1: 0.5515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 21/150, Loss: 0.1841, Accuracy: 0.9779, F1: 0.8019\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 22/150, Loss: 0.3023, Accuracy: 0.9333, F1: 0.5482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 22/150, Loss: 0.1913, Accuracy: 0.9756, F1: 0.7704\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 23/150, Loss: 0.2850, Accuracy: 0.9316, F1: 0.5658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 23/150, Loss: 0.1880, Accuracy: 0.9760, F1: 0.7767\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 24/150, Loss: 0.2717, Accuracy: 0.9257, F1: 0.5679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 24/150, Loss: 0.1818, Accuracy: 0.9753, F1: 0.7760\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 25/150, Loss: 0.2548, Accuracy: 0.9327, F1: 0.5696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 25/150, Loss: 0.1736, Accuracy: 0.9803, F1: 0.7964\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 26/150, Loss: 0.2532, Accuracy: 0.9374, F1: 0.5634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 26/150, Loss: 0.1707, Accuracy: 0.9786, F1: 0.7916\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 27/150, Loss: 0.2528, Accuracy: 0.9470, F1: 0.6035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 27/150, Loss: 0.1838, Accuracy: 0.9684, F1: 0.7349\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 28/150, Loss: 0.2396, Accuracy: 0.9495, F1: 0.5992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 28/150, Loss: 0.1670, Accuracy: 0.9788, F1: 0.7912\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 29/150, Loss: 0.2357, Accuracy: 0.9504, F1: 0.5981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 29/150, Loss: 0.1620, Accuracy: 0.9812, F1: 0.8056\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 30/150, Loss: 0.2314, Accuracy: 0.9501, F1: 0.5992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 30/150, Loss: 0.1708, Accuracy: 0.9723, F1: 0.7561\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 31/150, Loss: 0.2294, Accuracy: 0.9536, F1: 0.6073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 31/150, Loss: 0.1676, Accuracy: 0.9740, F1: 0.7625\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 32/150, Loss: 0.2246, Accuracy: 0.9510, F1: 0.6027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 32/150, Loss: 0.1572, Accuracy: 0.9807, F1: 0.8024\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 33/150, Loss: 0.2129, Accuracy: 0.9522, F1: 0.6036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 33/150, Loss: 0.1557, Accuracy: 0.9810, F1: 0.8036\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 34/150, Loss: 0.2129, Accuracy: 0.9568, F1: 0.6103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 34/150, Loss: 0.1571, Accuracy: 0.9797, F1: 0.7942\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 35/150, Loss: 0.2093, Accuracy: 0.9543, F1: 0.6080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 35/150, Loss: 0.1549, Accuracy: 0.9814, F1: 0.8026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 36/150, Loss: 0.2101, Accuracy: 0.9525, F1: 0.6055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 36/150, Loss: 0.1780, Accuracy: 0.9654, F1: 0.7100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 37/150, Loss: 0.2154, Accuracy: 0.9539, F1: 0.6190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 37/150, Loss: 0.1512, Accuracy: 0.9820, F1: 0.8060\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 38/150, Loss: 0.2062, Accuracy: 0.9550, F1: 0.6138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 38/150, Loss: 0.1473, Accuracy: 0.9825, F1: 0.8126\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 39/150, Loss: 0.2070, Accuracy: 0.9537, F1: 0.5999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 39/150, Loss: 0.1521, Accuracy: 0.9786, F1: 0.7870\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 40/150, Loss: 0.2039, Accuracy: 0.9558, F1: 0.6067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 40/150, Loss: 0.1644, Accuracy: 0.9676, F1: 0.7251\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 41/150, Loss: 0.2030, Accuracy: 0.9562, F1: 0.6152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 41/150, Loss: 0.1514, Accuracy: 0.9786, F1: 0.7875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 42/150, Loss: 0.1971, Accuracy: 0.9552, F1: 0.6126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 42/150, Loss: 0.1431, Accuracy: 0.9885, F1: 0.8425\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 43/150, Loss: 0.1997, Accuracy: 0.9577, F1: 0.6082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 43/150, Loss: 0.1480, Accuracy: 0.9810, F1: 0.8013\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 44/150, Loss: 0.1967, Accuracy: 0.9555, F1: 0.6142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 44/150, Loss: 0.1534, Accuracy: 0.9760, F1: 0.7700\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 45/150, Loss: 0.1974, Accuracy: 0.9581, F1: 0.6211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 45/150, Loss: 0.1476, Accuracy: 0.9790, F1: 0.7922\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 46/150, Loss: 0.1906, Accuracy: 0.9551, F1: 0.6201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 46/150, Loss: 0.1391, Accuracy: 0.9857, F1: 0.8255\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 47/150, Loss: 0.1926, Accuracy: 0.9619, F1: 0.6234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 47/150, Loss: 0.1489, Accuracy: 0.9779, F1: 0.7794\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 48/150, Loss: 0.1865, Accuracy: 0.9565, F1: 0.6210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 48/150, Loss: 0.1513, Accuracy: 0.9734, F1: 0.7568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 49/150, Loss: 0.1915, Accuracy: 0.9629, F1: 0.6342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 49/150, Loss: 0.1390, Accuracy: 0.9853, F1: 0.8187\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 50/150, Loss: 0.1863, Accuracy: 0.9622, F1: 0.6267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 50/150, Loss: 0.1404, Accuracy: 0.9823, F1: 0.8082\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 51/150, Loss: 0.1900, Accuracy: 0.9597, F1: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 51/150, Loss: 0.1424, Accuracy: 0.9790, F1: 0.7915\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 52/150, Loss: 0.1835, Accuracy: 0.9618, F1: 0.6262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 52/150, Loss: 0.1367, Accuracy: 0.9851, F1: 0.8217\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 53/150, Loss: 0.1868, Accuracy: 0.9617, F1: 0.6233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 53/150, Loss: 0.1354, Accuracy: 0.9870, F1: 0.8329\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 54/150, Loss: 0.1888, Accuracy: 0.9596, F1: 0.6270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 54/150, Loss: 0.1443, Accuracy: 0.9779, F1: 0.7825\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 55/150, Loss: 0.1834, Accuracy: 0.9633, F1: 0.6382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 55/150, Loss: 0.1492, Accuracy: 0.9749, F1: 0.7600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 56/150, Loss: 0.1809, Accuracy: 0.9638, F1: 0.6369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 56/150, Loss: 0.1387, Accuracy: 0.9827, F1: 0.8091\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 57/150, Loss: 0.1778, Accuracy: 0.9600, F1: 0.6277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 57/150, Loss: 0.1336, Accuracy: 0.9862, F1: 0.8270\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 58/150, Loss: 0.1768, Accuracy: 0.9659, F1: 0.6363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 58/150, Loss: 0.1360, Accuracy: 0.9855, F1: 0.8189\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 59/150, Loss: 0.1779, Accuracy: 0.9670, F1: 0.6426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 59/150, Loss: 0.1394, Accuracy: 0.9827, F1: 0.8025\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 60/150, Loss: 0.1768, Accuracy: 0.9642, F1: 0.6375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 60/150, Loss: 0.1432, Accuracy: 0.9766, F1: 0.7772\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 61/150, Loss: 0.1790, Accuracy: 0.9641, F1: 0.6395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 61/150, Loss: 0.1407, Accuracy: 0.9805, F1: 0.7917\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 62/150, Loss: 0.1824, Accuracy: 0.9638, F1: 0.6305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 62/150, Loss: 0.1305, Accuracy: 0.9883, F1: 0.8350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 63/150, Loss: 0.1807, Accuracy: 0.9655, F1: 0.6338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 63/150, Loss: 0.1356, Accuracy: 0.9851, F1: 0.8150\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 64/150, Loss: 0.1756, Accuracy: 0.9621, F1: 0.6387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 64/150, Loss: 0.1465, Accuracy: 0.9753, F1: 0.7657\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 65/150, Loss: 0.1738, Accuracy: 0.9671, F1: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 65/150, Loss: 0.1335, Accuracy: 0.9859, F1: 0.8215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 66/150, Loss: 0.1745, Accuracy: 0.9674, F1: 0.6451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 66/150, Loss: 0.1315, Accuracy: 0.9872, F1: 0.8271\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 67/150, Loss: 0.1690, Accuracy: 0.9644, F1: 0.6379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 67/150, Loss: 0.1310, Accuracy: 0.9866, F1: 0.8264\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 68/150, Loss: 0.1737, Accuracy: 0.9659, F1: 0.6365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 68/150, Loss: 0.1373, Accuracy: 0.9831, F1: 0.8035\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 69/150, Loss: 0.1713, Accuracy: 0.9663, F1: 0.6478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 69/150, Loss: 0.1294, Accuracy: 0.9870, F1: 0.8298\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 70/150, Loss: 0.1694, Accuracy: 0.9662, F1: 0.6473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 70/150, Loss: 0.1284, Accuracy: 0.9890, F1: 0.8371\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 71/150, Loss: 0.1674, Accuracy: 0.9693, F1: 0.6486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 71/150, Loss: 0.1441, Accuracy: 0.9764, F1: 0.7694\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 72/150, Loss: 0.1717, Accuracy: 0.9683, F1: 0.6492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 72/150, Loss: 0.1392, Accuracy: 0.9803, F1: 0.7900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 73/150, Loss: 0.1696, Accuracy: 0.9701, F1: 0.6567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 73/150, Loss: 0.1265, Accuracy: 0.9913, F1: 0.8583\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 74/150, Loss: 0.1715, Accuracy: 0.9637, F1: 0.6336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 74/150, Loss: 0.1262, Accuracy: 0.9900, F1: 0.8440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 75/150, Loss: 0.1690, Accuracy: 0.9654, F1: 0.6453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 75/150, Loss: 0.1433, Accuracy: 0.9775, F1: 0.7747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 76/150, Loss: 0.1676, Accuracy: 0.9672, F1: 0.6496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 76/150, Loss: 0.1394, Accuracy: 0.9775, F1: 0.7785\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 77/150, Loss: 0.1695, Accuracy: 0.9677, F1: 0.6520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 77/150, Loss: 0.1259, Accuracy: 0.9896, F1: 0.8431\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 78/150, Loss: 0.1681, Accuracy: 0.9708, F1: 0.6529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 78/150, Loss: 0.1265, Accuracy: 0.9894, F1: 0.8443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 79/150, Loss: 0.1630, Accuracy: 0.9687, F1: 0.6482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 79/150, Loss: 0.1317, Accuracy: 0.9831, F1: 0.8055\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 80/150, Loss: 0.1662, Accuracy: 0.9731, F1: 0.6668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 80/150, Loss: 0.1364, Accuracy: 0.9807, F1: 0.7966\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 81/150, Loss: 0.1660, Accuracy: 0.9673, F1: 0.6547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 81/150, Loss: 0.1290, Accuracy: 0.9881, F1: 0.8297\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 82/150, Loss: 0.1602, Accuracy: 0.9711, F1: 0.6581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 82/150, Loss: 0.1253, Accuracy: 0.9913, F1: 0.8472\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 83/150, Loss: 0.1634, Accuracy: 0.9703, F1: 0.6576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 83/150, Loss: 0.1302, Accuracy: 0.9864, F1: 0.8253\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 84/150, Loss: 0.1628, Accuracy: 0.9715, F1: 0.6654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 84/150, Loss: 0.1315, Accuracy: 0.9851, F1: 0.8115\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 85/150, Loss: 0.1645, Accuracy: 0.9731, F1: 0.6626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 85/150, Loss: 0.1271, Accuracy: 0.9898, F1: 0.8403\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 86/150, Loss: 0.1597, Accuracy: 0.9698, F1: 0.6569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 86/150, Loss: 0.1277, Accuracy: 0.9898, F1: 0.8372\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 87/150, Loss: 0.1577, Accuracy: 0.9746, F1: 0.6660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 87/150, Loss: 0.1307, Accuracy: 0.9842, F1: 0.8129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 88/150, Loss: 0.1587, Accuracy: 0.9727, F1: 0.6660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 88/150, Loss: 0.1253, Accuracy: 0.9909, F1: 0.8438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 89/150, Loss: 0.1574, Accuracy: 0.9708, F1: 0.6535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 89/150, Loss: 0.1219, Accuracy: 0.9931, F1: 0.8542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 90/150, Loss: 0.1581, Accuracy: 0.9753, F1: 0.6633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 90/150, Loss: 0.1257, Accuracy: 0.9909, F1: 0.8435\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 91/150, Loss: 0.1594, Accuracy: 0.9722, F1: 0.6621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 91/150, Loss: 0.1280, Accuracy: 0.9896, F1: 0.8368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 92/150, Loss: 0.1529, Accuracy: 0.9718, F1: 0.6631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 92/150, Loss: 0.1266, Accuracy: 0.9885, F1: 0.8356\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 93/150, Loss: 0.1557, Accuracy: 0.9722, F1: 0.6596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 93/150, Loss: 0.1283, Accuracy: 0.9877, F1: 0.8260\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 94/150, Loss: 0.1546, Accuracy: 0.9747, F1: 0.6716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 94/150, Loss: 0.1257, Accuracy: 0.9898, F1: 0.8408\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 95/150, Loss: 0.1525, Accuracy: 0.9725, F1: 0.6579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 95/150, Loss: 0.1255, Accuracy: 0.9894, F1: 0.8390\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 96/150, Loss: 0.1556, Accuracy: 0.9745, F1: 0.6671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 96/150, Loss: 0.1220, Accuracy: 0.9929, F1: 0.8503\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 97/150, Loss: 0.1534, Accuracy: 0.9734, F1: 0.6659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 97/150, Loss: 0.1198, Accuracy: 0.9933, F1: 0.8532\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 98/150, Loss: 0.1511, Accuracy: 0.9749, F1: 0.6722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 98/150, Loss: 0.1190, Accuracy: 0.9944, F1: 0.8575\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 99/150, Loss: 0.1493, Accuracy: 0.9727, F1: 0.6649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 99/150, Loss: 0.1189, Accuracy: 0.9952, F1: 0.8616\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 100/150, Loss: 0.1524, Accuracy: 0.9777, F1: 0.6736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 100/150, Loss: 0.1232, Accuracy: 0.9939, F1: 0.8530\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 101/150, Loss: 0.1520, Accuracy: 0.9723, F1: 0.6668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 101/150, Loss: 0.1329, Accuracy: 0.9838, F1: 0.8044\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 102/150, Loss: 0.1500, Accuracy: 0.9790, F1: 0.6822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 102/150, Loss: 0.1233, Accuracy: 0.9926, F1: 0.8484\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 103/150, Loss: 0.1479, Accuracy: 0.9812, F1: 0.6815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 103/150, Loss: 0.1191, Accuracy: 0.9963, F1: 0.8671\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 104/150, Loss: 0.1532, Accuracy: 0.9766, F1: 0.6701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 104/150, Loss: 0.1182, Accuracy: 0.9946, F1: 0.8588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 105/150, Loss: 0.1492, Accuracy: 0.9763, F1: 0.6721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 105/150, Loss: 0.1356, Accuracy: 0.9829, F1: 0.8033\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 106/150, Loss: 0.1450, Accuracy: 0.9779, F1: 0.6795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 106/150, Loss: 0.1225, Accuracy: 0.9944, F1: 0.8522\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 107/150, Loss: 0.1507, Accuracy: 0.9764, F1: 0.6764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 107/150, Loss: 0.1217, Accuracy: 0.9946, F1: 0.8539\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 108/150, Loss: 0.1462, Accuracy: 0.9740, F1: 0.6650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 108/150, Loss: 0.1185, Accuracy: 0.9959, F1: 0.8700\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 109/150, Loss: 0.1451, Accuracy: 0.9817, F1: 0.6830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 109/150, Loss: 0.1213, Accuracy: 0.9950, F1: 0.8541\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 110/150, Loss: 0.1480, Accuracy: 0.9803, F1: 0.6837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 110/150, Loss: 0.1309, Accuracy: 0.9868, F1: 0.8270\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 111/150, Loss: 0.1469, Accuracy: 0.9776, F1: 0.6790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 111/150, Loss: 0.1299, Accuracy: 0.9875, F1: 0.8196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 112/150, Loss: 0.1459, Accuracy: 0.9797, F1: 0.6801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 112/150, Loss: 0.1206, Accuracy: 0.9946, F1: 0.8575\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 113/150, Loss: 0.1470, Accuracy: 0.9779, F1: 0.6819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 113/150, Loss: 0.1247, Accuracy: 0.9913, F1: 0.8442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 114/150, Loss: 0.1426, Accuracy: 0.9784, F1: 0.6764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 114/150, Loss: 0.1222, Accuracy: 0.9935, F1: 0.8487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 115/150, Loss: 0.1509, Accuracy: 0.9785, F1: 0.6780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 115/150, Loss: 0.1280, Accuracy: 0.9916, F1: 0.8452\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 116/150, Loss: 0.1388, Accuracy: 0.9821, F1: 0.6892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 116/150, Loss: 0.1187, Accuracy: 0.9965, F1: 0.8585\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 117/150, Loss: 0.1471, Accuracy: 0.9804, F1: 0.6826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 117/150, Loss: 0.1167, Accuracy: 0.9976, F1: 0.8742\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 118/150, Loss: 0.1447, Accuracy: 0.9825, F1: 0.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 118/150, Loss: 0.1189, Accuracy: 0.9965, F1: 0.8635\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 119/150, Loss: 0.1409, Accuracy: 0.9787, F1: 0.6823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 119/150, Loss: 0.1229, Accuracy: 0.9931, F1: 0.8517\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 120/150, Loss: 0.1402, Accuracy: 0.9777, F1: 0.6807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 120/150, Loss: 0.1278, Accuracy: 0.9900, F1: 0.8339\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 121/150, Loss: 0.1419, Accuracy: 0.9872, F1: 0.7008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 121/150, Loss: 0.1189, Accuracy: 0.9950, F1: 0.8583\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 122/150, Loss: 0.1382, Accuracy: 0.9815, F1: 0.6855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 122/150, Loss: 0.1176, Accuracy: 0.9959, F1: 0.8617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 123/150, Loss: 0.1376, Accuracy: 0.9823, F1: 0.6844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 123/150, Loss: 0.1168, Accuracy: 0.9996, F1: 0.8764\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 124/150, Loss: 0.1396, Accuracy: 0.9830, F1: 0.6906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 124/150, Loss: 0.1193, Accuracy: 0.9955, F1: 0.8593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 125/150, Loss: 0.1370, Accuracy: 0.9817, F1: 0.6899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 125/150, Loss: 0.1187, Accuracy: 0.9978, F1: 0.8717\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 126/150, Loss: 0.1383, Accuracy: 0.9841, F1: 0.6894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 126/150, Loss: 0.1177, Accuracy: 0.9963, F1: 0.8636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 127/150, Loss: 0.1374, Accuracy: 0.9782, F1: 0.6783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 127/150, Loss: 0.1187, Accuracy: 0.9974, F1: 0.8719\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 128/150, Loss: 0.1374, Accuracy: 0.9791, F1: 0.6767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 128/150, Loss: 0.1175, Accuracy: 0.9965, F1: 0.8630\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 129/150, Loss: 0.1371, Accuracy: 0.9828, F1: 0.6859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 129/150, Loss: 0.1193, Accuracy: 0.9963, F1: 0.8647\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 130/150, Loss: 0.1335, Accuracy: 0.9848, F1: 0.6945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 130/150, Loss: 0.1257, Accuracy: 0.9939, F1: 0.8513\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 131/150, Loss: 0.1328, Accuracy: 0.9856, F1: 0.7007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 131/150, Loss: 0.1366, Accuracy: 0.9868, F1: 0.8195\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 132/150, Loss: 0.1349, Accuracy: 0.9870, F1: 0.7044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 132/150, Loss: 0.1202, Accuracy: 0.9959, F1: 0.8634\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 133/150, Loss: 0.1336, Accuracy: 0.9823, F1: 0.6928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 133/150, Loss: 0.1187, Accuracy: 0.9965, F1: 0.8663\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 134/150, Loss: 0.1319, Accuracy: 0.9875, F1: 0.7006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 134/150, Loss: 0.1200, Accuracy: 0.9955, F1: 0.8612\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 135/150, Loss: 0.1300, Accuracy: 0.9843, F1: 0.6962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 135/150, Loss: 0.1336, Accuracy: 0.9894, F1: 0.8320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 136/150, Loss: 0.1318, Accuracy: 0.9829, F1: 0.6948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 136/150, Loss: 0.1370, Accuracy: 0.9875, F1: 0.8211\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 137/150, Loss: 0.1311, Accuracy: 0.9818, F1: 0.6881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 137/150, Loss: 0.1194, Accuracy: 0.9952, F1: 0.8591\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 138/150, Loss: 0.1361, Accuracy: 0.9799, F1: 0.6797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 138/150, Loss: 0.1162, Accuracy: 0.9961, F1: 0.8721\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 139/150, Loss: 0.1339, Accuracy: 0.9825, F1: 0.6832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 139/150, Loss: 0.1156, Accuracy: 0.9985, F1: 0.8773\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 140/150, Loss: 0.1370, Accuracy: 0.9846, F1: 0.6931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 140/150, Loss: 0.1158, Accuracy: 0.9961, F1: 0.8738\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 141/150, Loss: 0.1356, Accuracy: 0.9864, F1: 0.6934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 141/150, Loss: 0.1201, Accuracy: 0.9970, F1: 0.8657\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 142/150, Loss: 0.1318, Accuracy: 0.9870, F1: 0.6981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 142/150, Loss: 0.1226, Accuracy: 0.9942, F1: 0.8537\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 143/150, Loss: 0.1281, Accuracy: 0.9833, F1: 0.6953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 143/150, Loss: 0.1257, Accuracy: 0.9920, F1: 0.8448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 144/150, Loss: 0.1295, Accuracy: 0.9866, F1: 0.7008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 144/150, Loss: 0.1192, Accuracy: 0.9955, F1: 0.8608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 145/150, Loss: 0.1308, Accuracy: 0.9854, F1: 0.6974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 145/150, Loss: 0.1179, Accuracy: 0.9968, F1: 0.8706\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 146/150, Loss: 0.1279, Accuracy: 0.9869, F1: 0.7032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 146/150, Loss: 0.1197, Accuracy: 0.9965, F1: 0.8643\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 147/150, Loss: 0.1296, Accuracy: 0.9884, F1: 0.7041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 147/150, Loss: 0.1256, Accuracy: 0.9922, F1: 0.8460\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 148/150, Loss: 0.1279, Accuracy: 0.9885, F1: 0.7041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 148/150, Loss: 0.1162, Accuracy: 0.9983, F1: 0.8759\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 149/150, Loss: 0.1253, Accuracy: 0.9864, F1: 0.7014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 149/150, Loss: 0.1156, Accuracy: 0.9972, F1: 0.8740\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 150/150, Loss: 0.1272, Accuracy: 0.9876, F1: 0.7008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 150/150, Loss: 0.1176, Accuracy: 0.9959, F1: 0.8664\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Initialize WandB\n",
    "wandb.init(project='NLP_AS2-Q3-P1', name='glv-D2-ff-cc', config={'epoch': 150, 'batch_size': 256})\n",
    "\n",
    "# Assuming you have a BiLSTM_CRF model, a train_dataloader, a val_dataloader, and an optimizer\n",
    "# Also assuming you have defined the necessary variables (e.g., vocab_size, tag_to_ix, etc.)\n",
    "\n",
    "# Move the model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "import torch\n",
    "\n",
    "def calculate_accuracy(predictions, targets, sen_lengths):\n",
    "    ranges = targets.shape[0]\n",
    "    target = targets.cpu()\n",
    "    predictions = torch.tensor(predictions).cpu()\n",
    "    acc = 0\n",
    "\n",
    "    for i in range(ranges):\n",
    "        prex = predictions[i][:sen_lengths[i]+1]\n",
    "        trex = target[i][:sen_lengths[i]+1]\n",
    "        acc += torch.sum(prex == trex)\n",
    "\n",
    "    # Move the division outside the loop to calculate the average accuracy\n",
    "    acc = acc.float() / (sum(sen_lengths)+10)\n",
    "    # print(acc)\n",
    "    return acc\n",
    "\n",
    "def aggregater(predictions, targets, sen_lengths):\n",
    "    ranges = targets.shape[0]\n",
    "    target = targets.cpu()\n",
    "    predictions = torch.tensor(predictions).cpu()\n",
    "    acc = 0\n",
    "    aggr_pred = []\n",
    "    aggr_targ = []\n",
    "    for i in range(ranges):\n",
    "        prex = predictions[i][:sen_lengths[i]]\n",
    "        trex = target[i][:sen_lengths[i]]\n",
    "        aggr_pred.extend(prex)\n",
    "        aggr_targ.extend(trex)\n",
    "    return aggr_pred,aggr_targ\n",
    "\n",
    "# WandB Config\n",
    "config = wandb.config\n",
    "\n",
    "# Watch the model\n",
    "wandb.watch(model)\n",
    "\n",
    "for epoch in range(config.epoch):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_loss_train = 0\n",
    "    correct_predictions_train = 0\n",
    "    total_sentences_train = 0\n",
    "    predictions_q = []\n",
    "    traget_q = []\n",
    "\n",
    "    for sentence_in, targets, mask, sen_lengths in tqdm(dataloader, desc=f'Training Epoch {epoch + 1}/{config.epoch}', leave=False):\n",
    "        sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        loss = model(sentence_in, mask, targets, sen_lengths)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss = torch.sum(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print('loss ',loss)\n",
    "        # Accumulate loss for the epoch\n",
    "        total_loss_train += (loss.item()/torch.sum(sen_lengths))\n",
    "\n",
    "        # Prediction\n",
    "        predictions_train = model.predict(sentence_in, mask, sen_lengths)\n",
    "        correct_predictions_train += calculate_accuracy(predictions_train, targets, sen_lengths)\n",
    "\n",
    "        temp_pred,temp_trag = aggregater(predictions_train, targets, sen_lengths)\n",
    "\n",
    "        predictions_q.extend(temp_pred)\n",
    "        traget_q.extend(temp_trag)\n",
    "\n",
    "        # Update total sentences count\n",
    "        # total_sentences_train += sentence_in.size(0)\n",
    "\n",
    "    # Calculate average loss and accuracy for training\n",
    "    average_loss_train = total_loss_train / len(dataloader)\n",
    "    accuracy_train = correct_predictions_train / len(dataloader)  # Average over all sentences, not just batches\n",
    "    f1_Score= f1_score(traget_q, predictions_q, average=\"macro\")\n",
    "\n",
    "    # Log metrics to WandB\n",
    "    wandb.log({'Train Loss': average_loss_train, 'Train Accuracy': accuracy_train, 'Train F1': f1_Score}, step=epoch)\n",
    "    print(f'Training Epoch {epoch + 1}/{150}, Loss: {average_loss_train:.4f}, Accuracy: {accuracy_train:.4f}, F1: {f1_Score :.4f}')\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_loss_val = 0\n",
    "    correct_predictions_val = 0\n",
    "    total_sentences_val = 0\n",
    "    predictions_p = []\n",
    "    traget_p = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_val, desc=f'Validation Epoch {epoch + 1}/{config.epoch}', leave=False):\n",
    "            sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            loss_val = model(sentence_in, mask, targets, sen_lengths)\n",
    "            total_loss_val += (torch.sum(loss_val).item()/torch.sum(sen_lengths))\n",
    "\n",
    "            # Prediction\n",
    "            predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
    "            correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
    "\n",
    "            temp_pred,temp_trag = aggregater(predictions_val, targets, sen_lengths)\n",
    "\n",
    "            predictions_p.extend(temp_pred)\n",
    "            traget_p.extend(temp_trag)\n",
    "\n",
    "            # Update total sentences count\n",
    "            # total_sentences_val += sentence_in.size(0)\n",
    "\n",
    "    # Calculate average loss and accuracy for validation\n",
    "    average_loss_val = total_loss_val / len(dataloader_val)\n",
    "    accuracy_val = correct_predictions_val / len(dataloader_val)  # Average over all sentences, not just batches\n",
    "    f1_Score = f1_score(traget_p, predictions_p, average=\"macro\")\n",
    "\n",
    "    # Log metrics to WandB\n",
    "    wandb.log({'Validation Loss': average_loss_val, 'Validation Accuracy': accuracy_val, 'Validation F1': f1_Score}, step=epoch)\n",
    "    print(f'Validation Epoch {epoch + 1}/{150}, Loss: {average_loss_val:.4f}, Accuracy: {accuracy_val:.4f}, F1: {f1_Score:.4f}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "jsluZV6ArICu"
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import torch\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# # Assuming you have a BiLSTM_CRF model, a train_dataloader, a val_dataloader, and an optimizer\n",
    "# # Also assuming you have defined the necessary variables (e.g., vocab_size, tag_to_ix, etc.)\n",
    "\n",
    "# # Move the model to GPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Function to calculate accuracy\n",
    "# import torch\n",
    "\n",
    "# def calculate_accuracy(predictions, targets, sen_lengths):\n",
    "#     ranges = targets.shape[0]\n",
    "#     target = targets.cpu()\n",
    "#     predictions = torch.tensor(predictions).cpu()\n",
    "#     acc = 0\n",
    "\n",
    "#     for i in range(ranges):\n",
    "#         prex = predictions[i][:sen_lengths[i]]\n",
    "#         trex = target[i][:sen_lengths[i]]\n",
    "#         acc += torch.sum(prex == trex)\n",
    "\n",
    "#     # Move the division outside the loop to calculate the average accuracy\n",
    "#     acc = acc.float() / sum(sen_lengths)\n",
    "#     # print(acc)\n",
    "#     return acc\n",
    "\n",
    "# def aggregater(predictions, targets, sen_lengths):\n",
    "#     ranges = targets.shape[0]\n",
    "#     target = targets.cpu()\n",
    "#     predictions = torch.tensor(predictions).cpu()\n",
    "#     acc = 0\n",
    "#     aggr_pred = []\n",
    "#     aggr_targ = []\n",
    "#     for i in range(ranges):\n",
    "#         prex = predictions[i][:sen_lengths[i]]\n",
    "#         trex = target[i][:sen_lengths[i]]\n",
    "#         aggr_pred.extend(prex)\n",
    "#         aggr_targ.extend(trex)\n",
    "#     return aggr_pred,aggr_targ\n",
    "\n",
    "\n",
    "# for epoch in range(300):\n",
    "#     # Training\n",
    "#     model.train()\n",
    "#     total_loss_train = 0\n",
    "#     correct_predictions_train = 0\n",
    "#     total_sentences_train = 0\n",
    "#     predictions_q = []\n",
    "#     traget_q = []\n",
    "\n",
    "#     for sentence_in, targets, mask, sen_lengths in tqdm(dataloader, desc=f'Training Epoch {epoch + 1}/{300}', leave=False):\n",
    "#         sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "#         model.zero_grad()\n",
    "\n",
    "#         # Forward pass\n",
    "#         loss = model(sentence_in, mask, targets, sen_lengths)\n",
    "\n",
    "#         # Backward pass and optimization\n",
    "#         loss = torch.sum(loss)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # print('loss ',loss)\n",
    "#         # Accumulate loss for the epoch\n",
    "#         total_loss_train += (loss.item()/torch.sum(sen_lengths))\n",
    "\n",
    "#         # Prediction\n",
    "#         predictions_train = model.predict(sentence_in, mask, sen_lengths)\n",
    "#         correct_predictions_train += calculate_accuracy(predictions_train, targets, sen_lengths)\n",
    "\n",
    "#         temp_pred,temp_trag = aggregater(predictions_train, targets, sen_lengths)\n",
    "\n",
    "#         predictions_q.extend(temp_pred)\n",
    "#         traget_q.extend(temp_trag)\n",
    "\n",
    "#         # Update total sentences count\n",
    "#         # total_sentences_train += sentence_in.size(0)\n",
    "\n",
    "#     # Calculate average loss and accuracy for training\n",
    "\n",
    "#     average_loss_train = total_loss_train / len(dataloader)\n",
    "#     accuracy_train = correct_predictions_train / len(dataloader)  # Average over all sentences, not just batches\n",
    "#     f1_Score= f1_score(traget_q, predictions_q, average=\"macro\")\n",
    "#     print(f'Training Epoch {epoch + 1}/{300}, Loss: {average_loss_train:.4f}, Accuracy: {accuracy_train:.4f}, F1: {f1_Score :.4f}')\n",
    "\n",
    "#     # Validation\n",
    "#     model.eval()\n",
    "#     total_loss_val = 0\n",
    "#     correct_predictions_val = 0\n",
    "#     total_sentences_val = 0\n",
    "#     predictions_p = []\n",
    "#     traget_p = []\n",
    "#     with torch.no_grad():\n",
    "#         for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_val, desc=f'Validation Epoch {epoch + 1}/{300}', leave=False):\n",
    "#             sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "#             # Forward pass\n",
    "#             loss_val = model(sentence_in, mask, targets, sen_lengths)\n",
    "#             total_loss_val += (torch.sum(loss_val).item()/torch.sum(sen_lengths))\n",
    "\n",
    "#             # Prediction\n",
    "#             predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
    "#             correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
    "\n",
    "\n",
    "#             temp_pred,temp_trag = aggregater(predictions_val, targets, sen_lengths)\n",
    "\n",
    "#             predictions_p.extend(temp_pred)\n",
    "#             traget_p.extend(temp_trag)\n",
    "\n",
    "#             # Update total sentences count\n",
    "#             # total_sentences_val += sentence_in.size(0)\n",
    "\n",
    "#     # Calculate average loss and accuracy for validation\n",
    "#     average_loss_val = total_loss_val / len(dataloader_val)\n",
    "#     accuracy_val = correct_predictions_val / len(dataloader_val)  # Average over all sentences, not just batches\n",
    "#     f1_Score = f1_score(traget_p, predictions_p, average=\"macro\")\n",
    "#     print(f'Validation Epoch {epoch + 1}/{300}, Loss: {average_loss_val:.4f}, Accuracy: {accuracy_val:.4f}, F1: {f1_Score:.4f}')\n",
    "\n",
    "#     print()\n",
    "\n",
    "# # # Training and validation loop\n",
    "# # for epoch in range(300):\n",
    "# #     # Training\n",
    "# #     model.train()\n",
    "# #     total_loss_train = 0\n",
    "# #     correct_predictions_train = 0\n",
    "# #     total_sentences_train = 0\n",
    "\n",
    "# #     for sentence_in, targets, mask, sen_lengths in tqdm(dataloader, desc=f'Training Epoch {epoch + 1}/{300}', leave=False):\n",
    "# #         sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "# #         model.zero_grad()\n",
    "\n",
    "# #         # Forward pass\n",
    "# #         loss = model(sentence_in, mask, targets, sen_lengths)\n",
    "\n",
    "# #         # Backward pass and optimization\n",
    "# #         loss = torch.sum(loss)\n",
    "# #         loss.backward()\n",
    "# #         optimizer.step()\n",
    "\n",
    "# #         # Accumulate loss for the epoch\n",
    "# #         total_loss_train += loss.item()\n",
    "\n",
    "# #         # Prediction\n",
    "# #         predictions_train = model.predict(sentence_in, mask, sen_lengths)\n",
    "# #         print()\n",
    "# #         # print(len(predictions_train[0]),'predi_len')\n",
    "# #         # print(sen_lengths[0],'sen_len')\n",
    "# #         # print(targets[0][:sen_lengths[0]].shape,'targets_len')\n",
    "# #         correct_predictions_train += calculate_accuracy(predictions_train, targets, sen_lengths)\n",
    "\n",
    "# #         # Update total sentences count\n",
    "# #         total_sentences_train += sentence_in.size(0)\n",
    "\n",
    "# #     # Calculate average loss and accuracy for training\n",
    "# #     average_loss_train = total_loss_train / total_sentences_train\n",
    "# #     accuracy_train = correct_predictions_train / len(dataloader)\n",
    "\n",
    "# #     print(f'Training Epoch {epoch + 1}/{300}, Loss: {average_loss_train:.4f}, Accuracy: {accuracy_train:.4f}')\n",
    "\n",
    "# #     # Validation\n",
    "# #     model.eval()\n",
    "# #     total_loss_val = 0\n",
    "# #     correct_predictions_val = 0\n",
    "# #     total_sentences_val = 0\n",
    "\n",
    "# #     with torch.no_grad():\n",
    "# #         for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_val, desc=f'Validation Epoch {epoch + 1}/{300}', leave=False):\n",
    "# #             sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "# #             # Forward pass\n",
    "# #             loss_val = model(sentence_in, mask, targets, sen_lengths)\n",
    "# #             total_loss_val += torch.sum(loss_val).item()\n",
    "\n",
    "# #             # Prediction\n",
    "# #             predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
    "# #             correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
    "\n",
    "# #             # Update total sentences count\n",
    "# #             total_sentences_val += sentence_in.size(0)\n",
    "\n",
    "# #     # Calculate average loss and accuracy for validation\n",
    "# #     average_loss_val = total_loss_val / total_sentences_val\n",
    "# #     accuracy_val = correct_predictions_val / len(dataloader_val)\n",
    "\n",
    "# #     print(f'Validation Epoch {epoch + 1}/{300}, Loss: {average_loss_val:.4f}, Accuracy: {accuracy_val:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQB_sic2fKxK",
    "outputId": "6e242807-0fe2-4e5c-cc37-6a7a97999068",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt: pytorch save model code\n",
    "\n",
    "torch.save(model.state_dict(), 'model_d2_glv.pth')\n",
    "\n",
    "# Save the model to W&B\n",
    "wandb.save(\"'model_d2_glv.pth'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING PHASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class BiLSTMCRF(nn.Module):\n",
    "    def __init__(self, tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256):\n",
    "        \"\"\" Initialize the model\n",
    "        Args:\n",
    "            sent_vocab (Vocab): vocabulary of words\n",
    "            tag_vocab (Vocab): vocabulary of tags\n",
    "            embed_size (int): embedding size\n",
    "            hidden_size (int): hidden state size\n",
    "        \"\"\"\n",
    "        super(BiLSTMCRF, self).__init__()\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # self.sent_vocab = sent_vocab\n",
    "        self.tag_vocab = tag_vocab\n",
    "        # self.embedding = nn.Embedding(len(sent_vocab), embed_size) print\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, bidirectional=True)\n",
    "        self.hidden2emit_score = nn.Linear(hidden_size * 2, len(self.tag_vocab))\n",
    "        self.transition = nn.Parameter(torch.randn(len(self.tag_vocab), len(self.tag_vocab)))  # shape: (K, K)\n",
    "\n",
    "    def forward(self, sentences,mask, tags, sen_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "                                of the longest sentence\n",
    "            tags (tensor): corresponding tags, shape (b, len)\n",
    "            sen_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            loss (tensor): loss on the batch, shape (b,)\n",
    "        \"\"\"\n",
    "        # mask = (sentences != self.sent_vocab[self.sent_vocab.PAD])  # shape: (b, len)                        #$$$$$$$$$$$$$$$$$$$__________________\n",
    "        sentences = sentences.transpose(0, 1)  # shape: (len, b)\n",
    "        # print(\"forword--1\",sentences.shape)\n",
    "        # sentences = self.embedding(sentences)  # shape: (len, b, e)\n",
    "        emit_score = self.encode(sentences, sen_lengths)  # shape: (b, len, K)\n",
    "        # print(\"forword--2\",sentences.shape)\n",
    "        loss = self.cal_loss(tags, mask, emit_score)  # shape: (b,)\n",
    "        return loss\n",
    "\n",
    "    def encode(self, sentences, sent_lengths):\n",
    "        \"\"\" BiLSTM Encoder\n",
    "        Args:\n",
    "            sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
    "            sent_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            emit_score (tensor): emit score, shape (b, len, K)\n",
    "        \"\"\"\n",
    "        # padded_sentences = pack_padded_sequence(sentences, sent_lengths)\n",
    "        hidden_states, _ = self.encoder(sentences)\n",
    "        # print(hidden_states.shape,\"(((())))\")\n",
    "        hidden_states = hidden_states.permute(1,0,2)\n",
    "        # hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
    "        # print(hidden_states.shape)\n",
    "        emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
    "        emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
    "        return emit_score\n",
    "\n",
    "    # def encode(self, sentences, sent_lengths):\n",
    "    #   \"\"\" BiLSTM Encoder\n",
    "    #   Args:\n",
    "    #       sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
    "    #       sent_lengths (list): sentence lengths\n",
    "    #   Returns:\n",
    "    #       emit_score (tensor): emit score, shape (b, len, K)\n",
    "    #   \"\"\"\n",
    "    #   sorted_lengths, sorted_idx = torch.sort(sent_lengths, descending=True)\n",
    "    #   sorted_sentences = sentences[:, sorted_idx, :]  # Sort the sentences based on lengths\n",
    "    #   packed_sentences = pack_padded_sequence(sorted_sentences, sorted_lengths)\n",
    "    #   hidden_states, _ = self.encoder(packed_sentences)\n",
    "    #   hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
    "    #   emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
    "    #   emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
    "    #   return emit_score\n",
    "\n",
    "    def cal_loss(self, tags, mask, emit_score):\n",
    "        \"\"\" Calculate CRF loss\n",
    "        Args:\n",
    "            tags (tensor): a batch of tags, shape (b, len)\n",
    "            mask (tensor): mask for the tags, shape (b, len), values in PAD position is 0\n",
    "            emit_score (tensor): emit matrix, shape (b, len, K)\n",
    "        Returns:\n",
    "            loss (tensor): loss of the batch, shape (b,)\n",
    "        \"\"\"\n",
    "        batch_size, sent_len = tags.shape\n",
    "        # calculate score for the tags\n",
    "        score = torch.gather(emit_score, dim=2, index=tags.unsqueeze(dim=2)).squeeze(dim=2)  # shape: (b, len)\n",
    "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
    "        total_score = (score * mask.type(torch.float)).sum(dim=1)  # shape: (b,)\n",
    "        # calculate the scaling factor\n",
    "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "        fix_length = 100\n",
    "        # for i in range(1, sent_len):\n",
    "        for i in range(1, fix_length):\n",
    "            n_unfinished = mask[:, i].sum()\n",
    "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "            emit_and_transition = emit_score[: n_unfinished, i].unsqueeze(dim=1) + self.transition  # shape: (uf, K, K)\n",
    "            log_sum = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "            max_v = log_sum.max(dim=1)[0].unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
    "            log_sum = log_sum - max_v  # shape: (uf, K, K)\n",
    "            d_uf = max_v + torch.logsumexp(log_sum, dim=1).unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
    "            d = torch.cat((d_uf, d[n_unfinished:]), dim=0)\n",
    "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "        max_d = d.max(dim=-1)[0]  # shape: (b,)\n",
    "        d = max_d + torch.logsumexp(d - max_d.unsqueeze(dim=1), dim=1)  # shape: (b,)\n",
    "        llk = total_score - d  # shape: (b,)\n",
    "        loss = -llk  # shape: (b,)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def predict(self, sentences, mask, sen_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "                                of the longest sentence\n",
    "            sen_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            tags (list[list[str]]): predicted tags for the batch\n",
    "        \"\"\"\n",
    "        batch_size = sentences.shape[0]\n",
    "\n",
    "        w = mask\n",
    "        sentences = sentences.transpose(0, 1)\n",
    "\n",
    "        emit_score = self.encode(sentences, sen_lengths)\n",
    "\n",
    "        # Initialize the tags with all possible tag indices for each sentence in the batch\n",
    "        tags = [[[i] for i in range(len(self.tag_vocab))]] * batch_size  # list, shape: (b, K, 1)\n",
    "\n",
    "        # Initialize the first column of the dynamic programming matrix\n",
    "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "\n",
    "        # Use a fixed length (e.g., 100) instead of max(sen_lengths)\n",
    "        fixed_length = 100\n",
    "\n",
    "        # Iterate over the remaining columns of the dynamic programming matrix\n",
    "        for i in range(1, fixed_length):\n",
    "            # Calculate the number of unfinished sentences at the current position\n",
    "            n_unfinished = mask[:, i].sum()\n",
    "\n",
    "            # Slice the dynamic programming matrix for the unfinished sentences\n",
    "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "\n",
    "            # Compute emission and transition scores for the current position\n",
    "            emit_and_transition = self.transition + emit_score[: n_unfinished, i].unsqueeze(dim=1)  # shape: (uf, K, K)\n",
    "\n",
    "            # Compute the new values for the dynamic programming matrix\n",
    "            new_d_uf = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "\n",
    "            # Update the dynamic programming matrix and get the indices of maximum values\n",
    "            d_uf, max_idx = torch.max(new_d_uf, dim=1)\n",
    "            max_idx = max_idx.tolist()  # list, shape: (nf, K)\n",
    "\n",
    "            # Update the tags for the unfinished sentences\n",
    "            tags[: n_unfinished] = [[tags[b][k] + [j] for j, k in enumerate(max_idx[b])] for b in range(n_unfinished)]\n",
    "\n",
    "            # Concatenate the new values to the dynamic programming matrix\n",
    "            d = torch.cat((torch.unsqueeze(d_uf, dim=1), d[n_unfinished:]), dim=0)  # shape: (b, 1, K)\n",
    "\n",
    "        # Remove the singleton dimension to get the final dynamic programming matrix\n",
    "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "\n",
    "        # Get the indices of the maximum values in the final column of the matrix\n",
    "        _, max_idx = torch.max(d, dim=1)  # shape: (b,)\n",
    "        max_idx = max_idx.tolist()\n",
    "\n",
    "        # Extract the predicted tags based on the maximum indices\n",
    "        tags = [tags[b][k] for b, k in enumerate(max_idx)]\n",
    "\n",
    "        # Print the predicted tags and sentence lengths for debugging\n",
    "        # print(tags, sen_lengths, '((()))')\n",
    "\n",
    "        return tags\n",
    "\n",
    "tag_to_ix ={'O': 0, 'B': 1, 'I':2,'<START>':3,'<STOP>':4,'<PAD>':5}\n",
    "# tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
    "model  = BiLSTMCRF(tag_to_ix,dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "import torch\n",
    "\n",
    "def calculate_accuracy(predictions, targets, sen_lengths):\n",
    "    ranges = targets.shape[0]\n",
    "    target = targets.cpu()\n",
    "    predictions = torch.tensor(predictions).cpu()\n",
    "    acc = 0\n",
    "\n",
    "    for i in range(ranges):\n",
    "        prex = predictions[i][:sen_lengths[i]+1]\n",
    "        trex = target[i][:sen_lengths[i]+1]\n",
    "        acc += torch.sum(prex == trex)\n",
    "\n",
    "    # Move the division outside the loop to calculate the average accuracy\n",
    "    acc = acc.float() / (sum(sen_lengths)+10)\n",
    "    # print(acc)\n",
    "    return acc\n",
    "\n",
    "def aggregater(predictions, targets, sen_lengths):\n",
    "    ranges = targets.shape[0]\n",
    "    target = targets.cpu()\n",
    "    predictions = torch.tensor(predictions).cpu()\n",
    "    acc = 0\n",
    "    aggr_pred = []\n",
    "    aggr_targ = []\n",
    "    for i in range(ranges):\n",
    "        prex = predictions[i][:sen_lengths[i]]\n",
    "        trex = target[i][:sen_lengths[i]]\n",
    "        aggr_pred.extend(prex)\n",
    "        aggr_targ.extend(trex)\n",
    "    return aggr_pred,aggr_targ\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import gensim.downloader as api\n",
    "from torchtext.vocab import GloVe\n",
    "# import fasttext\n",
    "import numpy as np\n",
    "# import fasttext.util\n",
    "import json\n",
    "\n",
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, json_path, embedding_type='word2vec',load=True):\n",
    "        with open(json_path, 'r') as file:\n",
    "            self.data = json.load(file)\n",
    "\n",
    "        self.embedding_type = embedding_type\n",
    "        if load:\n",
    "          self.embedding_model =self.load_embedding_model()\n",
    "        else:\n",
    "          self.embedding_model = None\n",
    "\n",
    "    def load_embedding_model(self):\n",
    "        if self.embedding_type == 'word2vec':\n",
    "            # Download the pre-trained Word2Vec model\n",
    "            return api.load('word2vec-google-news-300')\n",
    "        elif self.embedding_type == 'glove':\n",
    "            # Download the pre-trained GloVe model (6B tokens, 300d)\n",
    "            return GloVe(name='6B', dim=300)\n",
    "        elif self.embedding_type == 'fasttext':\n",
    "            # Load the pre-trained FastText model\n",
    "            fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "            ft = fasttext.load_model('cc.en.300.bin')\n",
    "            return fasttext.load_model('cc.en.300.bin')  # Adjust the path based on your downloaded model\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "\n",
    "    def text_to_embeddings(self, text):\n",
    "        maxlen = 100\n",
    "        if self.embedding_type == 'word2vec':\n",
    "            # Word2Vec embeddings\n",
    "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(self.embedding_model.vector_size) for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            embeddings = [torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]\n",
    "\n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "\n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((self.embedding_model.vector_size,),-1.0))\n",
    "\n",
    "\n",
    "        elif self.embedding_type == 'glove':\n",
    "            # GloVe embeddings\n",
    "            embeddings = [self.embedding_model[word]  for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
    "\n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "\n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
    "\n",
    "        elif self.embedding_type == 'fasttext':\n",
    "            # FastText embeddings\n",
    "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(sentiment_dataset.embedding_model['a'].shape[0]) for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
    "\n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "\n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "        # print()\n",
    "        return np.stack(embeddings)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "\n",
    "        index = str(index)\n",
    "        text = self.data[index][\"text\"]\n",
    "        labels = self.data[index][\"labels\"]\n",
    "\n",
    "        # Convert text to embeddings\n",
    "        text_embeddings = torch.tensor(self.text_to_embeddings(text))\n",
    "        # print(text_embeddings.shape)\n",
    "        # torch.stack([torch.full((1,text_embeddings.shape[1]),-1000),text_embeddings, [torch.full((1,text_embeddings.shape[1]),1000)])\n",
    "        current_length = len(labels)\n",
    "\n",
    "        labels = ['<START>'] + labels + ['<STOP>']\n",
    "\n",
    "        sent_lengths =torch.tensor(len(labels))\n",
    "\n",
    "        max_length = 100\n",
    "        labels = labels + ['<PAD>'] * (max_length - (current_length+2))\n",
    "\n",
    "        # Convert labels to numerical format if needed\n",
    "        label_mapping = {'O': 0, 'B': 1, 'I':2,'<START>':3,'<STOP>':4,'<PAD>':5}                               # bind it to self__________________________\n",
    "        numerical_labels = [label_mapping[label] for label in labels ]\n",
    "\n",
    "\n",
    "        # Pad the sequence to the maximum length\n",
    "\n",
    "        # Convert labels to PyTorch tensor\n",
    "        labels_tensor = torch.tensor(numerical_labels)\n",
    "        mask = torch.hstack([torch.full((text_embeddings.shape[0],),True),torch.full((100-text_embeddings.shape[0],),False)])\n",
    "        # print(labels_tensor.shape,text_embeddings.shape,mask.shape)\n",
    "        return text_embeddings, labels_tensor, mask,sent_lengths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = torch.load('t2_model4_glove.pt')\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "json_path = 'ATE_test.json'\n",
    "embedding_type = 'glove'\n",
    "sentiment_dataset_test = SentimentAnalysisDataset(json_path, embedding_type)\n",
    "sentiment_dataset =sentiment_dataset_test\n",
    "# sentiment_dataset_test.embedding_model = sentiment_dataset.embedding_model\n",
    "batch_size  = 512\n",
    "dataloader_test = DataLoader(sentiment_dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LtLXbDKMZ1bG",
    "outputId": "c728506c-69a6-4640-a264-655e7000d413"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.9796\n",
      "Test F1:  0.8319482704772927\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "model.eval()\n",
    "correct_predictions_val = 0\n",
    "total_sentences_val = 0\n",
    "predictions_r = []\n",
    "traget_r = []\n",
    "epoch=1\n",
    "device='cuda'\n",
    "with torch.no_grad():\n",
    "    for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_test, desc=f'Test Epoch {epoch + 1}/{300}', leave=False):\n",
    "        sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "        # Prediction\n",
    "        predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
    "        correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
    "        temp_pred,temp_trag = aggregater(predictions_val, targets, sen_lengths)\n",
    "        predictions_r.extend(temp_pred)\n",
    "        traget_r.extend(temp_trag)\n",
    "\n",
    "accuracy_val = correct_predictions_val / len(dataloader_test)  # Average over all sentences, not just batches\n",
    "print()\n",
    "print(f'Test Accuracy: {accuracy_val:.4f}')\n",
    "print(f'Test F1:  {f1_score(traget_r, predictions_r, average=\"macro\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371,
     "referenced_widgets": [
      "c3c25fe6f8524f979d612c699973bc13",
      "730e08ad0b9a431894168771c340cc51",
      "713ce3fc547c480aa5f2d7e58671fc77",
      "9360e05f96c5438d9d6eddd48998db3f",
      "52ef274b259c4282919a07ddd0add679",
      "fad8339f87ff4dcaa694cc1e3a6de186",
      "0dc4fa5ec6c548d296f0363836e82ac0",
      "2abfc549409f4e4a8bb22ceef5d88b81"
     ]
    },
    "id": "6O3vYN9J-BBQ",
    "outputId": "973f5173-42f6-4d7d-bfd4-ee572f6e5dee"
   },
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01f19ee3c41d4453922eadc27e4aebbe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cec9bf164bf4843a65b6c49cb2ba8ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63961d90d5c243ccb3873be0a41d9f0e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6826f2f8776c4f64b566c7d2eb7aada8",
      "value": 1
     }
    },
    "0dc4fa5ec6c548d296f0363836e82ac0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2abfc549409f4e4a8bb22ceef5d88b81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52ef274b259c4282919a07ddd0add679": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63961d90d5c243ccb3873be0a41d9f0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6826f2f8776c4f64b566c7d2eb7aada8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "713ce3fc547c480aa5f2d7e58671fc77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0dc4fa5ec6c548d296f0363836e82ac0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2abfc549409f4e4a8bb22ceef5d88b81",
      "value": 1
     }
    },
    "730e08ad0b9a431894168771c340cc51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52ef274b259c4282919a07ddd0add679",
      "placeholder": "",
      "style": "IPY_MODEL_fad8339f87ff4dcaa694cc1e3a6de186",
      "value": "0.057 MB of 0.057 MB uploaded\r"
     }
    },
    "9360e05f96c5438d9d6eddd48998db3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad4e07d0d4af40a7bbec5532c247509e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b951c48572d14bff8ce7ed3973bbc5e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad4e07d0d4af40a7bbec5532c247509e",
      "placeholder": "",
      "style": "IPY_MODEL_de667a0bfcfe4f309becaca01c776e41",
      "value": "0.033 MB of 0.033 MB uploaded\r"
     }
    },
    "c3c25fe6f8524f979d612c699973bc13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_730e08ad0b9a431894168771c340cc51",
       "IPY_MODEL_713ce3fc547c480aa5f2d7e58671fc77"
      ],
      "layout": "IPY_MODEL_9360e05f96c5438d9d6eddd48998db3f"
     }
    },
    "c9efc196b9ec47ddbb80f91ebf9c89ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b951c48572d14bff8ce7ed3973bbc5e1",
       "IPY_MODEL_0cec9bf164bf4843a65b6c49cb2ba8ec"
      ],
      "layout": "IPY_MODEL_01f19ee3c41d4453922eadc27e4aebbe"
     }
    },
    "de667a0bfcfe4f309becaca01c776e41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fad8339f87ff4dcaa694cc1e3a6de186": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
